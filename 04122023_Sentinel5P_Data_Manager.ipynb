{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3625d7b-974a-4255-a7f1-f016665c3cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,timedelta\n",
    "# import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "# print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88734cc-7698-43c4-80ac-906c16f23bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEE Authentication\n",
    "# Either use the credentials approach using a json file or Authenticate\n",
    "# service_account = 'serviceaccount.com'\n",
    "# credentials = ee.ServiceAccountCredentials(service_account, 'location/to/json/file.json')\n",
    "# ee.Initialize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5efe47-afbd-4d9d-bbe5-92b7c4bc4e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e3759d-ac04-4bbf-9d6d-3535e1ebc120",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37ffc96-69a6-45b4-a295-652eab4e0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Shapefile Address\n",
    "file_path = r\"Input\\SHapefile\\location.shp\"\n",
    "AOI = geemap.shp_to_ee(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f140692-de50-4d19-82f8-cbec61bd0a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function clips all images to AOI\n",
    "def clipper(image):\n",
    "    return image.clip(aoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f65b575-61a6-4efb-8d44-5f359a2f081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code tries to generate a list of dates that the collection will be created upon\n",
    "# This approach is useful when the collection may be too big to be computed at once\n",
    "def date_list_maker(st0,et0):\n",
    "    from datetime import datetime,timedelta\n",
    "    \n",
    "    # Convert input strings to datetime objects\n",
    "    start_date = datetime.strptime(st0, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(et0, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Initialize a list to store the result\n",
    "    date_range = []\n",
    "    \n",
    "    # Define the interval in days (60 days in this case)\n",
    "    interval = timedelta(days=60)\n",
    "    \n",
    "    # Start with the input start date and add intervals until it's less than or equal to the end date\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        next_date = current_date + interval\n",
    "        if next_date <= end_date:\n",
    "            date_range.append((current_date.strftime(\"%Y-%m-%d\"), next_date.strftime(\"%Y-%m-%d\")))\n",
    "        else:\n",
    "            date_range.append((current_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")))\n",
    "        current_date = next_date\n",
    "    \n",
    "    return date_range\n",
    "\n",
    "from datetime import date,timedelta\n",
    "import datetime\n",
    "\n",
    "# df0 = pd.DataFrame()\n",
    "def sabkucch_2(st,et):\n",
    "    \n",
    "    # Define the collection\n",
    "    dataset = ee.ImageCollection(collection) \\\n",
    "                    .filterDate(st, et) \\\n",
    "                    .filterBounds(aoi) \\\n",
    "                    .select(band) \\\n",
    "                    .map(clipper)\n",
    "    \n",
    "    # This function adds the mean, upper and lower percentile of each image into the metadata of the image\n",
    "    def func_fsn(img):\n",
    "        mn = img.reduceRegion(ee.Reducer.mean(),aoi).get(band)\n",
    "        bp = ee.Image(img.reduceRegion(ee.Reducer.percentile([5]),aoi).get(band))\n",
    "        up = ee.Image(img.reduceRegion(ee.Reducer.percentile([95]),aoi).get(band))\n",
    "        return img.set({ \n",
    "            'mn': mn,\n",
    "            'bp': bp,\n",
    "            'up': up\n",
    "        })\n",
    "    \n",
    "    dataset = dataset.map(func_fsn)\n",
    "    \n",
    "    # Filtering images that do not have mean, upper and lower percentile, i.e., images that do not have pixels in the AOI\n",
    "    dataset = dataset.filterMetadata('mn', 'not_equals', None) \\\n",
    "                    .filterMetadata('bp', 'not_equals', None) \\\n",
    "                       .filterMetadata('up', 'not_equals', None)\n",
    "\n",
    "    # Removes extreme values in the image\n",
    "    def chipper(image):\n",
    "        bp = ee.Image(image.reduceRegion(ee.Reducer.percentile([5]),aoi).get(band))\n",
    "        up = ee.Image(image.reduceRegion(ee.Reducer.percentile([95]),aoi).get(band))\n",
    "        a = image.select(band)\n",
    "        mask = a.gte(ee.Number(bp)).And(a.lte(ee.Number(up))).And(a.gte(ee.Number(0)))\n",
    "        return image.updateMask(mask)\n",
    "    \n",
    "    dataset = dataset.map(chipper)\n",
    "    \n",
    "    # dataset.size().getInfo()\n",
    "    \n",
    "    # dataset.getInfo()\n",
    "    \n",
    "    # def index_maker(col0):\n",
    "    # Function to add a Moving Index Property to an image\n",
    "    def addIndex(image, newIndex):\n",
    "        return image.set('Moving_index', newIndex)\n",
    "    \n",
    "    # Iterate through the collection and add the property\n",
    "    # Declaring Empty Collection to be filled after adding Moving Index Property\n",
    "    X_collection = ee.ImageCollection([])\n",
    "    newIndex = 0\n",
    "    for i in range(dataset.size().getInfo()):\n",
    "        image = ee.Image(dataset.toList(dataset.size()).get(i))\n",
    "        modified_image = addIndex(image, newIndex)\n",
    "        X_collection = X_collection.merge(ee.ImageCollection([modified_image]))\n",
    "        newIndex += 1\n",
    "    \n",
    "    def process_list(list_data):\n",
    "            def compute_daily_mean(image):\n",
    "                date = image.date().format('YYYY-MM-dd')\n",
    "                mean_CO = image.reduceRegion(ee.Reducer.mean(), AOI).get(band)\n",
    "                # return ee.List({'date': date, 'mean_CO': mean_CO})\n",
    "                if mean_CO is None:\n",
    "                    return ee.Feature(None, {'Date': date, 'Mean': -9999})\n",
    "                else:\n",
    "                    return ee.Feature(None, {'Date': date, 'Mean': mean_CO})\n",
    "            \n",
    "        \n",
    "            daily_means = list_data.map(compute_daily_mean)\n",
    "            \n",
    "            # daily_means\n",
    "            \n",
    "            df = pd.DataFrame(daily_means.getInfo()['features'])\n",
    "            # Initialize empty lists to store extracted 'date' and 'mean_CO'\n",
    "            dates = []\n",
    "            mean_COs = []\n",
    "            \n",
    "            # Iterate through the 'properties' column and extract 'date' and 'mean_CO'\n",
    "            for prop in df['properties']:\n",
    "                if 'Mean' in prop:\n",
    "                    mean_COs.append(prop['Mean'])\n",
    "                    dates.append(prop['Date'])\n",
    "            \n",
    "            # Create a new DataFrame with 'date' and 'mean_CO' columns\n",
    "            new_df = pd.DataFrame({'Date': dates, 'Mean': mean_COs})\n",
    "            \n",
    "            # Reset the index of the new DataFrame\n",
    "            new_df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            # Print the resulting DataFrame\n",
    "            # print(new_df)\n",
    "            return new_df\n",
    "    \n",
    "    df = process_list(X_collection)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444608e4-fe38-426f-a4c0-ec2a535bdf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "st0 = '2020-01-01'\n",
    "et0 = '2022-01-01'\n",
    "kryptonite_no = 52\n",
    "yr = 2022\n",
    "aoi = AOI\n",
    "gas = 'CO'\n",
    "factor = 1000\n",
    "collection = 'COPERNICUS/S5P/OFFL/L3_CO'\n",
    "band = 'CO_column_number_density'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffea8da9-bd98-4945-9fe0-09a329573653",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe089639-29a9-46c9-abe8-abcf41152563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yr,aoi,gas,collection,band = 2022,BDA,'SO2',\"COPERNICUS/S5P/NRTI/L3_SO2\",'SO2_column_number_density'\n",
    "for i in range(int(st0[0:4]),int(et0[0:4])+1):\n",
    "    print(datetime.datetime.now(),'Started',str(i)+'-01-01')\n",
    "    date_range_list = date_list_maker(str(i)+'-01-01',str(i+1)+'-01-01')\n",
    "    df0 = pd.DataFrame()\n",
    "    for st_d, et_d in date_range_list:\n",
    "        dfx = sabkucch_2(st_d,et_d)\n",
    "        df0 = pd.concat([df0, dfx], ignore_index=True)\n",
    "        print(datetime.datetime.now(),'Set')\n",
    "    fn = str(i)\n",
    "    try:\n",
    "        merged_doc_directory = os.path.join(current_working_directory,'Result')\n",
    "        os.makedirs(merged_doc_directory)\n",
    "    except:\n",
    "        merged_doc_directory = os.path.join(current_working_directory,'Result')\n",
    "\n",
    "    df0['Mean'] = df0['Mean']*factor\n",
    "    df0.to_csv(os.path.join(merged_doc_directory,f'{gas}_{fn}.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bef279-acdb-4198-a1e8-26e51b198724",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
