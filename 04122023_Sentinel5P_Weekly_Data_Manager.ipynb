{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160b9fb7-d453-41bb-aa18-f2b7400cde7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ee\n",
    "import geemap\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime,timedelta\n",
    "from datetime import date\n",
    "# import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "# print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee09d6ad-7907-4831-afc2-f6edfce589cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GEE Authentication\n",
    "# Either use the credentials approach using a json file or Authenticate\n",
    "# service_account = 'serviceaccount.com'\n",
    "# credentials = ee.ServiceAccountCredentials(service_account, 'location/to/json/file.json')\n",
    "# ee.Initialize(credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb9632a-808e-4e6b-92fc-df328f308dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b71333-a15e-49c3-9b86-6cff105dd613",
   "metadata": {},
   "outputs": [],
   "source": [
    "ee.Authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dce7c6-2430-4ecd-aed4-1b5b69fc6990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Shapefile Address\n",
    "file_path = r\"D:\\Pollutant\\01_Raw_Data\\BDA_Boundary\\BLR_BDABoundary_Py_GCS.shp\"\n",
    "AOI = geemap.shp_to_ee(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593e80ed-8813-4969-b5c6-0acbcd1bd090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function clips all images to AOI\n",
    "def clipper(image):\n",
    "    return image.clip(AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496f98e9-4997-4c27-b02b-daef1e63535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This part of the code tries to generate a list of dates that the collection will be created upon\n",
    "# This approach is useful when the collection may be too big to be computed at once\n",
    "def date_list_maker(st0,et0):\n",
    "    from datetime import datetime,timedelta\n",
    "    \n",
    "    # Convert input strings to datetime objects\n",
    "    start_date = datetime.strptime(st0, \"%Y-%m-%d\")\n",
    "    end_date = datetime.strptime(et0, \"%Y-%m-%d\")\n",
    "    \n",
    "    # Initialize a list to store the result\n",
    "    date_range = []\n",
    "    \n",
    "    # Define the interval in days (60 days in this case)\n",
    "    interval = timedelta(days=60)\n",
    "    \n",
    "    # Start with the input start date and add intervals until it's less than or equal to the end date\n",
    "    current_date = start_date\n",
    "    while current_date <= end_date:\n",
    "        next_date = current_date + interval\n",
    "        if next_date <= end_date:\n",
    "            date_range.append((current_date.strftime(\"%Y-%m-%d\"), next_date.strftime(\"%Y-%m-%d\")))\n",
    "        else:\n",
    "            date_range.append((current_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")))\n",
    "        current_date = next_date\n",
    "    \n",
    "    return date_range\n",
    "\n",
    "from datetime import date,timedelta\n",
    "import datetime\n",
    "\n",
    "# This part of the code pretty much does everything, hence the name\n",
    "def sabkucch(st,et):\n",
    "\n",
    "    # Declare Collection\n",
    "    dataset = ee.ImageCollection(collection) \\\n",
    "                    .filterDate(st, et) \\\n",
    "                    .filterBounds(AOI) \\\n",
    "                    .select(band) \\\n",
    "                    .map(clipper)\n",
    "\n",
    "    # This function adds the mean, upper and lower percentile of each image into the metadata of the image\n",
    "    def func_fsn(img):\n",
    "        mn = img.reduceRegion(ee.Reducer.mean(),AOI).get(band)\n",
    "        bp = ee.Image(img.reduceRegion(ee.Reducer.percentile([5]),AOI).get(band))\n",
    "        up = ee.Image(img.reduceRegion(ee.Reducer.percentile([95]),AOI).get(band))\n",
    "        return img.set({ \n",
    "            'mn': mn,\n",
    "            'bp': bp,\n",
    "            'up': up\n",
    "        })\n",
    "\n",
    "    dataset = dataset.map(func_fsn)\n",
    "    \n",
    "    # Filtering images that do not have mean, upper and lower percentile, i.e., images that do not have pixels in the AOI\n",
    "    dataset = dataset.filterMetadata('mn', 'not_equals', None) \\\n",
    "                    .filterMetadata('bp', 'not_equals', None) \\\n",
    "                       .filterMetadata('up', 'not_equals', None)\n",
    "    \n",
    "    # Removes extreme values in the image\n",
    "    def chipper(image):\n",
    "        bp = ee.Image(image.reduceRegion(ee.Reducer.percentile([5]),AOI).get(band))\n",
    "        up = ee.Image(image.reduceRegion(ee.Reducer.percentile([95]),AOI).get(band))\n",
    "        a = image.select(band)\n",
    "        mask = a.gte(ee.Number(bp)).And(a.lte(ee.Number(up))).And(a.gte(ee.Number(0)))\n",
    "        return image.updateMask(mask)\n",
    "    \n",
    "    dataset = dataset.map(chipper)\n",
    "\n",
    "    # this part creates a weekly \n",
    "    n = 7\n",
    "    start_date = date(int(st[0:4]),int(st[5:7]),int(st[8:10]))\n",
    "    end_date = date(int(et[0:4]),int(et[5:7]),int(et[8:10]))\n",
    "    \n",
    "    # Get number of weeks between the given dates\n",
    "    endWeek = round((end_date-start_date).days / 7)\n",
    "\n",
    "    # Create a list of week number\n",
    "    time_list = ee.List.sequence(0,endWeek-1)\n",
    "\n",
    "    # This function computes the mean of 7 days by taking input of time_list and comuting dates from the start date.\n",
    "    # The value of n can be increased to 15 or 30 or any other value based on the users requirement for creating 15 day or 30 day mean\n",
    "    def mover(day):\n",
    "            a = ee.Number.expression('day*x',\n",
    "                                 {'day' : day,\n",
    "                                  'x' : n  })\n",
    "            start2 = ee.Date(st).advance(a,'day')\n",
    "            img = dataset.select(band).filterDate(start2,start2.advance(n, 'day')) \\\n",
    "                  .reduce(ee.Reducer.mean()) \\\n",
    "                  .set('system:time_start',(start2.millis())) \\\n",
    "                  .set('id',day) \\\n",
    "                  .rename(band)\n",
    "            m = ee.Number(img.reduceRegion(ee.Reducer.mean(),AOI,1000).get(band))\n",
    "            return img.set({\n",
    "                'Date' : img.date().format('YYYY-MM-dd'),\n",
    "                'Mean':m})\n",
    "            \n",
    "    dataset = ee.ImageCollection.fromImages(time_list.map(mover))\n",
    "    # dataset.getInfo()\n",
    "    \n",
    "    # def index_maker(col0):\n",
    "    # Function to add a Moving Index Property to an image\n",
    "    def addIndex(image, newIndex):\n",
    "        return image.set('Moving_index', newIndex)\n",
    "    \n",
    "    # Iterate through the collection and add the property\n",
    "    # Declaring Empty Collection to be filled after adding Moving Index Property\n",
    "    X_collection = ee.ImageCollection([])\n",
    "    newIndex = 0\n",
    "    for i in range(dataset.size().getInfo()):\n",
    "        image = ee.Image(dataset.toList(dataset.size()).get(i))\n",
    "        modified_image = addIndex(image, newIndex)\n",
    "        X_collection = X_collection.merge(ee.ImageCollection([modified_image]))\n",
    "        newIndex += 1\n",
    "        \n",
    "    # Creating a new dataframe by taking the men values at initial date \n",
    "    def process_list(daily_means):\n",
    "        \n",
    "        df = pd.DataFrame(daily_means.getInfo()['features'])\n",
    "        # Initialize empty lists to store extracted 'date' and 'mean_CO'\n",
    "        dates = []\n",
    "        mean_COs = []\n",
    "        \n",
    "        # Iterate through the 'properties' column and extract 'date' and 'mean_CO'\n",
    "        for prop in df['properties']:\n",
    "            if 'Mean' in prop:\n",
    "                mean_COs.append(prop['Mean'])\n",
    "                dates.append(prop['Date'])\n",
    "        \n",
    "        # Create a new DataFrame with 'date' and 'mean_CO' columns\n",
    "        new_df = pd.DataFrame({'Date': dates, 'Mean': mean_COs})\n",
    "        \n",
    "        # Reset the index of the new DataFrame\n",
    "        new_df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        # Print the resulting DataFrame\n",
    "        # print(new_df)\n",
    "        return new_df\n",
    "\n",
    "    df = process_list(X_collection)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c27c1b-29ae-4a12-8a52-4cb6dc09a55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These variables may be adjusted by user for different Sentinel 5P pollutant products\n",
    "# The results will be calculated for all years included in the date range\n",
    "st0 = '2020-01-01'\n",
    "et0 = '2022-01-01'\n",
    "gas = 'CO'\n",
    "factor = 1000\n",
    "collection = 'COPERNICUS/S5P/OFFL/L3_CO'\n",
    "band = 'CO_column_number_density'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498c1a39-6910-4fee-8366-cb5f0648f63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Current Directory. User may choose to input their choice of directory\n",
    "current_working_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75124de0-c39d-4a3c-8d30-02de5406395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(int(st0[0:4]),int(et0[0:4])+1):\n",
    "    print(datetime.datetime.now(),'Started',str(i)+'-01-01')\n",
    "    date_range_list = date_list_maker(str(i)+'-01-01',str(i+1)+'-01-01')\n",
    "    df0 = pd.DataFrame()\n",
    "    for st_d, et_d in date_range_list:\n",
    "        dfx = sabkucch(st_d,et_d)\n",
    "        # print(dfx)\n",
    "        df0 = pd.concat([df0, dfx], ignore_index=True)\n",
    "        print(datetime.datetime.now(),'Set')\n",
    "    fn = str(i)\n",
    "    try:\n",
    "        merged_doc_directory = os.path.join(current_working_directory,'Result')\n",
    "        os.makedirs(merged_doc_directory)\n",
    "    except:\n",
    "        merged_doc_directory = os.path.join(current_working_directory,'Result')\n",
    "\n",
    "    df0['Mean'] = df0['Mean']*factor\n",
    "    df0.to_csv(os.path.join(merged_doc_directory,f'{gas}_{fn}.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
